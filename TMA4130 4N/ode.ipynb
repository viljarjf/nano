{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- KODE = \"ja\", \"nei\", default \"ja\" -->\n",
    "\n",
    "<!-- dom:TITLE: Numerical solution of ordinary differential equations  -->\n",
    "# Numerical solution of ordinary differential equations \n",
    "<!-- dom:AUTHOR: Anne Kværnø -->\n",
    "<!-- Author: -->  \n",
    "**Anne Kværnø**\n",
    "\n",
    "Date: **Oct 27, 2020**\n",
    "\n",
    "$\\newcommand{mb}[1]{\\mathbf{#1}}$\n",
    "\n",
    "With revisions by **Markus Grasmair**.\n",
    "\n",
    "# Introduction\n",
    "The topic of this note is the numerical solution of systems of ordinary differential\n",
    "equations (ODEs). This has been discussed in previous courses, see for instance\n",
    "the webpage \n",
    "[Differensialligninger](https://wiki.math.ntnu.no/tma4100/tema/differentialequations)\n",
    "from Mathematics 1. \n",
    "\n",
    "### Scalar ODEs\n",
    "\n",
    "A scalar ODE is an equation of the form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y'(x) = f(x,y(x)), \\qquad y(x_0)=y_0,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $y'(x)=\\frac{dy}{dx}$. The *inital condition* $y(x_0)=y_0$ is required for a unique\n",
    "solution. \n",
    "\n",
    "**NB!** It is common to use the term *initial value problem (IVP)* for an ODE for which the inital value $y(x_0)=y_0$ is given, and we only are interested in the solution for $x>x_0$. In this note, only initial value problems are considered.  \n",
    "\n",
    "**Example 1:** \n",
    "The general solution of the ODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y'(x) = -2xy(x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "is the function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y(x) = C e^{-x^2},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $C$ is a constant that depends on the initial condition $y(x_0)$.\n",
    "For instance, we obtain for $x_0 = 0$ and $y(0) = 1$ the solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y(x) = e^{-x^2},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Systems of ODEs\n",
    "\n",
    "A system of $m$ ODEs is given by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "y_1' &= f_1(x,y_1,y_2,\\dotsc,y_m), & y_1(x_0) &= y_{1,0} \\\\ \n",
    "y_2' &= f_2(x,y_1,y_2,\\dotsc,y_m), & y_2(x_0) &= y_{2,0} \\\\ \n",
    "     &\\ \\vdots                      &          &\\vdots    \\\\ \n",
    "y_m' &= f_m(x,y_1,y_2,\\dotsc,y_m), & y_m(x_0) &= y_{m,0} \\\\ \n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or, more compactly, by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mb{y}'(x) = \\mb{f}(x, \\mb{y}(x)),  \\qquad \\mb{y}(x_0) = \\mb{y}_0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where we use boldface to denote vectors in $\\mathbb{R}^m$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mb{y}(x) = \\left( \\begin{array}{c} y_1(x) \\\\ y_2(x) \\\\ \\vdots \\\\ y_m(x) \\end{array} \\right), \\qquad\n",
    "\\mb{f}(x,\\mb{y}) = \\left( \\begin{array}{c} f_1(x,y_1,y_2,\\dotsc,y_m), \\\\ f_2(x,y_1,y_2,\\dotsc,y_m), \\\\ \\vdots \\\\ f_m(x,y_1,y_2,\\dotsc,y_m), \\end{array} \\right), \\qquad\n",
    "\\mb{y}_0 = \\left( \\begin{array}{c} y_{1,0} \\\\ y_{2,0} \\\\ \\vdots \\\\ y_{m,0} \\end{array} \\right),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 2:**\n",
    "[The Lotka-Volterra equation](https://en.wikipedia.org/wiki/Lotka–Volterra_equations) is a system of two ODEs describing the interaction between predators and prey over time. The system is given as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "y'(x) &= \\alpha y(x) - \\beta y(x) z(x), \\\\ \n",
    "z'(x) &= \\delta y(x)z(x) - \\gamma z(x).\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here $x$ denotes time, $y(x)$ describes the population of the prey species, and $z(x)$ the population of predators. \n",
    "The parameters $\\alpha$, $\\beta$, $\\delta$, and $\\gamma$ depend on the populations to be modelled.  \n",
    "\n",
    "### Higher order ODEs\n",
    "\n",
    "An initial value  ODE of order $m$ is given by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "u^{(m)} = f(x,u,u',\\dotsc,u^{(m-1)}), \\qquad u(x_0)=u_0, \\quad\n",
    "u'(x_0)=u'_0,\\quad  \\dotsc, \\quad u^{(m-1)}(x_0) = u^{(m-1)}_0.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here $u^{(1)} =u'$ and $u^{(m+1)}=\\frac{du^{(m)}}{dx}$ for $m>0$.\n",
    "\n",
    "**Example 3:**\n",
    "\n",
    "[Van der Pol's equation](https://en.wikipedia.org/wiki/Van_der_Pol_oscillator)\n",
    "is a second order differential equation, given by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "u^{(2)} = \\mu (1-u^2)u' - u, \\qquad u(0)=u_0, \\quad u'(0)=u'_0,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\mu>0$ is some constant.  Common choices for initial values are $u_0=2$ and $u'_0=0$.\n",
    "\n",
    "Later in the note we will see how such equations can be rewritten as a system of first order ODEs. \n",
    "Systems of higher order ODEs can be treated similarly.  \n",
    "\n",
    "\n",
    "# Numerical methods for solving ODEs\n",
    "In this note, we will discuss some techniques for the numerial solution\n",
    "of ordinary differential equations. For simplicity or presentation,\n",
    "we will develop and discuss these methods mostly based on scalar ODEs.\n",
    "The same methods, however, are equally applicable for systems of equations.\n",
    "\n",
    "All the methods that we will discuss are so-called *one-step methods*.\n",
    "Given the ODE and the initial values $(x_0,y_0)$, \n",
    "we choose some step size $h$ and let $x_1=x_0+h$. Based on this information,\n",
    "we calculate an approximation $y_1$ to $y(x_1)$.\n",
    "Then, we repeat this process starting from $(x_1,y_1)$\n",
    "in order to calculate an approximation $y_2$ of $y(x_2)$, where $x_2 = x_1 + h$.\n",
    "This process is repeated until some final point, here called $x_{end}$ is reached. \n",
    "\n",
    "In one-step methods, the approximation $y_{k+1}$ of $y(x_{k+1})$ does not depend\n",
    "on the values of $y_{k-1}$, $y_{k-2}$, \\ldots, $y_0$.\n",
    "The main alternative to this type of methods are *multi-step methods*,\n",
    "where the approximation $y_{k+1}$ of $y(x_{k+1})$ takes into account those\n",
    "values as well.\n",
    "\n",
    "It should be emphasized that this strategy only will find approximations to the\n",
    "exact solution in some discrete points $x_n$, $n=0,1,\\ldots$. \n",
    "\n",
    "\n",
    "# Euler's method\n",
    "Let us start with the simplest example, [Euler's method](https://wiki.math.ntnu.no/tma4100/tema/differentialequations?&#numeriske_losninger), known from Mathematics 1. \n",
    "\n",
    "We are given an IVP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y'(x) = f(x,y(x)), \\qquad y(x_0)=y_0.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose some step size $h$. The trick is as follows: \n",
    "\n",
    "Do a Taylor expansion (*Preliminaries*, section 4) of the exact (but unknown) solution $y(x_0+h)$ around $x_0$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y(x_0+h) = y(x_0) + h y'(x_0) + \\frac{1}{2}h^2 y''(x_0) + \\dotsm.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume the step size $h$ to be small, such that the solution is dominated by the first two terms.  In that case, these can be used as the numerical approximation in the next step:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y(x_0+h) \\approx  y(x_0) + h y'(x_0) = y_0 + hf(x_0, y_0)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "giving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y_1 = y_0 + hf(x_0,y_0).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeating this, results in \n",
    "**Euler's method.**\n",
    "\n",
    "* Given a function $f(x,y)$ and an initial value $(x_0,y_0)$.\n",
    "\n",
    "* Choose a step size $h$. \n",
    "\n",
    "* For $i=0,1,2,\\dotsc$ \n",
    "\n",
    "  * $\\displaystyle y_{n+1}  = y_{n} + h f(x_n, y_n)$, \n",
    "\n",
    "  * $x_{n+1}=x_n+h$.\n",
    "\n",
    "\n",
    "\n",
    "# Implementation\n",
    "We would like to make this implementation more like a test platform. It should\n",
    "be simple to implement and test methods other than Euler's. That is why the\n",
    "implementaion here is divided in two parts:\n",
    "\n",
    "* `ode_solver`: This is a generic solver, and can be used by other methods than Euler's. \n",
    "\n",
    "* `euler`:      This function performs one step of Euler's method. \n",
    "\n",
    "Start by calling the necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from numpy import *\n",
    "from numpy.linalg import norm\n",
    "from matplotlib.pyplot import *\n",
    "newparams = {'figure.figsize': (8.0, 4.0), 'axes.grid': True,\n",
    "             'lines.markersize': 8, 'lines.linewidth': 2,\n",
    "             'font.size': 14}\n",
    "rcParams.update(newparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def euler(f, x, y, h):\n",
    "    # One step of the Euler method\n",
    "    y_next = y + h*f(x, y)\n",
    "    x_next = x + h\n",
    "    return x_next, y_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ode_solver(f, x0, xend, y0, h, method=euler):\n",
    "    '''\n",
    "    Generic solver for ODEs\n",
    "       y' = f(x,y), y(a)=y0\n",
    "    Input: f, the integration interval x0 and xend, \n",
    "           the stepsize h and the method of choice.  \n",
    "      \n",
    "    Output: Arrays with the x- and the corresponding y-values. \n",
    "    '''\n",
    "    \n",
    "    # Initializing:\n",
    "    y_num = array([y0])    # Array for the solution y \n",
    "    x_num = array([x0])    # Array for the x-values\n",
    "\n",
    "    xn = x0                # Running values for x and y\n",
    "    yn = y0 \n",
    "\n",
    "    # Main loop\n",
    "    while xn < xend - 1.e-10:            # Buffer for truncation errors        \n",
    "        xn, yn = method(f, xn, yn, h)    # Do one step by the method of choice\n",
    "        \n",
    "        # Extend the arrays for x and y\n",
    "        y_num = concatenate((y_num, array([yn])))\n",
    "        x_num = append(x_num,xn)\n",
    "        \n",
    "    return x_num, y_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `method`, which performs one step with a given method, can be changed, but the call of the function has to be of the following form:\n",
    "\n",
    "`x_next, y_next = method(f, x, y, h)`. \n",
    "\n",
    "\n",
    "**Numerical example 1:**\n",
    "Test the implementation of Euler's method on the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y'(x) = -2xy(x), \\qquad y(0)=1, \\qquad 0 \\leq x \\leq 1,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which has the analytic solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y(x) = e^{-x^2}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try with different step sizes, for instance $h=0.1$, $h=0.05$ and $h=0.01$. In\n",
    "each case, compare the numerical solution with the exact one. \n",
    "\n",
    "The following script solves the equation numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Numerical experiment 1\n",
    "\n",
    "# The right hand side of the ODE\n",
    "def f(x, y):\n",
    "    return -2*x*y\n",
    "\n",
    "# The exact solution, for verification\n",
    "def y_exact(x):\n",
    "    return exp(-x**2)\n",
    "\n",
    "x0, xend = 0, 1               # Integration interval\n",
    "y0 = 1                        # Initial value for y\n",
    "h = 0.1                       # Stepsize\n",
    "\n",
    "# Solve the equation\n",
    "x_num, y_num = ode_solver(f, x0, xend, y0, h)\n",
    "\n",
    "# Plot of the exact solution\n",
    "x = linspace(x0, xend, 101)\n",
    "plot(x, y_exact(x))\n",
    "\n",
    "# Plot of the numerical solution\n",
    "plot(x_num, y_num, '.-')\n",
    "\n",
    "xlabel('x')\n",
    "ylabel('y(x)')\n",
    "legend(['Exact', 'Euler']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also make a plot of the error in each step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate and plot the error in the x-values\n",
    "error = y_exact(x_num)-y_num\n",
    "plot(x_num, error, '.-')\n",
    "xlabel('x')\n",
    "ylabel('Error in Eulers metode')\n",
    "print('Max error = ', max(abs(error)))  # Print the maximum error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Numerical exercise 1:**\n",
    "Repeat the example on a [logistic\n",
    "equation](https://en.wikipedia.org/wiki/Logistic_function#Applications), given\n",
    "by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y' = y(1-y), \\qquad y(0) = y_0,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on the interval $[0,10]$. Use $y_0=0.1$ as initial value.  For comparision, the exact solution is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y(x) = \\frac{1}{1-(1-\\frac{1}{y_0})e^{-x}}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve the equation numerically by using different step sizes $h$, and try\n",
    "different initial values. \n",
    "\n",
    "\n",
    "## Systems of ODEs\n",
    "Euler's method works equally well for systems of $m$ ODEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mb{y}'(x) = \\mb{f}(x, \\mb{y}(x)),  \\qquad \\mb{y}(x_0) = \\mb{y}_0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, Euler's method is defined as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mb{y}_{n+1} = \\mb{y}_n + h \\mb{f}(x_n, \\mb{y}_n), \\qquad n=0,\\dotsc,N-1.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation above can be used without any changes.  \n",
    "The only difference from the scalar ODE case is that $y_{n}\\in \\mathbb{R}^m$ and\n",
    "$\\mb{f}\\colon\\mathbb{R} \\times \\mathbb{R}^m \\rightarrow \\mathbb{R}^m$.\n",
    "That is, the function $\\mb{f}$ that defines the right hand side of the ODE\n",
    "takes a scalar $x$ and an array $\\mb{y}_n$ of length $m$ as inputs,\n",
    "and returns an array of length $m$.\n",
    "\n",
    "**Numerical example 2:**\n",
    "Solve the Lotka-Volterra equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "y_1'(x) &= \\alpha y_1(x) - \\beta y_1(x) y_2(x), & y_1(0) &=  y_{1,0}, \\\\ \n",
    "y_2'(x) &= \\delta y_1(x)y_2(x) - \\gamma y_2(x), & y_2(0) &= y_{2,0}.\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, use the parameters and initial values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\alpha=2,\\quad \\beta=1, \\quad \\delta=0.5,\\quad \\gamma=1, \\qquad y_{1,0}=2,\n",
    "\\quad y_{2,0} = 0.5.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve the equation over the interval $[0,20]$, and use $h=0.02$. Try also other\n",
    "step sizes, e.g. $h=0.1$ and $h=0.002$. \n",
    "\n",
    "**NB!** In this case, the exact solution is not known. What is known is that the\n",
    "solutions are periodic and positive. Is this the case for the numerical\n",
    "solutions as well? Check for different values of $h$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Numerical example 2, system of equations.\n",
    "\n",
    "# The right hand side of the ODE\n",
    "# NB! y is an array of dimension 2, and so is dy. \n",
    "def lotka_volterra(x, y):\n",
    "    alpha, beta, delta, gamma = 2, 1, 0.5, 1     # Set the parameters\n",
    "    dy = array([alpha*y[0]-beta*y[0]*y[1],       # \n",
    "                delta*y[0]*y[1]-gamma*y[1]])\n",
    "    return dy\n",
    "\n",
    "x0, xend = 0, 20            # Integration interval\n",
    "y0 = array([2, 0.5])        # Initital values\n",
    "\n",
    "# Solve the equation\n",
    "x_lv, y_lv = ode_solver(lotka_volterra, x0, xend, y0, h=0.02) \n",
    "\n",
    "# Plot the solution\n",
    "plot(x_lv,y_lv);\n",
    "xlabel('x')\n",
    "title('Lotka-Volterra equation')\n",
    "legend(['y1','y2'],loc=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Higher order ODEs\n",
    "\n",
    "What about higher order ODEs? Can they be solved by Euler's method as well?\n",
    "\n",
    "To that end, we consider the $m$-th order ODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "u^{(m)}(x) = f\\bigl(x, u(x), u'(x), \\dotsc, u^{(m-1)}\\bigr).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a unique solution, we assume that the initial values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "u(x_0), u'(x_0), u''(x_0), \\dotsc, u^{(m-1)}(x_0)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "are known. Such equations can be written as a system of first order ODEs by the\n",
    "following trick:\n",
    "\n",
    "Let"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y_1(x) = u(x), \\quad y_2(x) = u'(x), \\quad\n",
    "y_3(x) = u^{(2)}(x), \\quad \\dotsc \\quad, y_{m}(x) = u^{(m-1)}(x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "such that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "  y_1' &= y_2, & y_1(x_0) &= u(x_0), \\\\ \n",
    "  y_2' &= y_3, & y_2(x_0) &= u'(x_0), \\\\ \n",
    "       & \\vdots  && \\vdots\\\\ \n",
    "  y_{m-1}' &= y_m, & y_{m-1}(x_0) &= u^{(m-2)}(x_0), \\\\ \n",
    "  y_m' &= f(x, y_1, y_2, \\cdots, y_{m-1},y_m), & y_m(x_0) &= u^{(m-1)}(x_0).\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is nothing but a system of first order ODEs, and can be solved by Euler's\n",
    "method exactly as before.\n",
    "Note, though, that we are mainly interested in the first component\n",
    "of the solution, which corresponds to the original function $u$.\n",
    "\n",
    "**Numerical example 3:**\n",
    "\n",
    "The Van der Pol oscillator is described by the second order differential\n",
    "equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "u'' = \\mu (1-u^2)u' - u, \\qquad u(0)=u_0, \\quad u'(0)=u_0'.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be rewritten as a system of first order ODEs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "y_1' &= y_2, & y_1(0) &= u_0,  \\\\ \n",
    "y_2' &= \\mu(1-y_1^2)y_2 - y_1, & y_2(0) &= u_0'.\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let  $\\mu=2$, $u(0)=2$ and $u'(0)=0$ and solve the equation over the interval\n",
    "$[0,20]$, using  $h=0.1$. Play with different step sizes, and maybe also with\n",
    "different values of $\\mu$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Numerical example 3\n",
    "\n",
    "# Define the ODE\n",
    "def van_der_pol(x, y):\n",
    "    mu = 2\n",
    "    dy = array([y[1],\n",
    "                mu*(1-y[0]**2)*y[1]-y[0] ])\n",
    "    return dy\n",
    "\n",
    "# Solve the equation\n",
    "x_vdp, y_vdp = ode_solver(van_der_pol, x0=0, xend=20, y0=array([2,0]), h=0.1)\n",
    "\n",
    "# Plot the solution\n",
    "plot(x_vdp,y_vdp);\n",
    "xlabel('x')\n",
    "title('Van der Pol\\'s equation')\n",
    "legend(['y1','y2'],loc=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis\n",
    "\n",
    "When an ODE is solved by Euler's method over some interval $[x_0,x_{end}]$, how\n",
    "will the error at $x_{end}$ (or some arbitrary point) depend on the number of\n",
    "steps. Or more spesific, choose the number of steps $N$, let the step size be\n",
    "$h=(x_{end}-x_0)/N$, such that $x_{end}=x_N$, what can we say about the error $e_N = y(x_{end})-y_N$? \n",
    "\n",
    "**Numerical example 4:**\n",
    "Solve the equation of Example 1,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y'(x) = -2xy(x), \\qquad y(0)=1,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with exact solution $y(x) =  e^{-x^2}$, \n",
    "over the interval $[0,1]$.  Use different\n",
    "step sizes $h$, and for each $h$, measure the error at $x=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Numerical example 4\n",
    "def f(x, y):                # The right hand side of the ODE\n",
    "    return -2*x*y\n",
    "\n",
    "def y_exact(x):            # The exact solution\n",
    "    return exp(-x**2)\n",
    "\n",
    "h = 0.1                     # The stepsize\n",
    "x0, xend = 0, 1             # Integration interval\n",
    "y0 = 1                      # Initial value\n",
    "\n",
    "print('h           error\\n---------------------')\n",
    "\n",
    "# Main loop\n",
    "for n in range(10):\n",
    "    x_num, y_num = ode_solver(f, x0, xend, y0, h)   # Solve the equation \n",
    "    error = abs(y_exact(xend)-y_num[-1])            # Error at the end point\n",
    "    print(format('{:.3e}   {:.3e}'.format( h, error)))   \n",
    "    h = 0.5*h                                       # Reduce the stepsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table generated from this code shows that whenever the step size is reduced\n",
    "with a factor of 0.5, so is the error. Therefore, we expect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "|y(x_{end}) - y_N| \\approx C h, \\qquad h=\\frac{x_{end}-x_0}{N}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method seems to be of order 1, see *Preliminaries*, section 3.1.\n",
    "\n",
    "In the following we will prove that this is in fact the case. The\n",
    "error analysis will be done on a scalar equation, but it can as well be extended\n",
    "to systems of equations. \n",
    "\n",
    "## Local and global errors\n",
    "In this discussion we have to consider two kinds of errors: \n",
    "\n",
    "* *Local truncation error* $d_{n+1}$: This is the error done on one step, starting from $(x_n,y(x_n))$. \n",
    "\n",
    "* *Global error* $e_{n}$: This is the difference between the exact and the numerical solution after $n$ steps, that is $e_{n} = y(x_n)-y_n$. \n",
    "\n",
    "In the following, we will see how to express the local truncation error, and we will see how the global and the local errors are related. We will use all this to find an upper bound for the global error at the end point $x_N=x_{end}$. The technique described here is quite standard for this type of error analysis.\n",
    "\n",
    "Let us start with the local truncation error. Euler's method is nothing but the first two terms of the Taylor expansion of the exact solution. As a consequence, the local truncation error is the remainder term $R_{2}(x)$ (see *Preliminaries*, section 4):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "d_{n+1} = y(x_n+h) - \\big( y(x_n) + h y'(x_n) \\big) = \\frac{1}{2}h^2 y''(\\xi), \\qquad \\xi \\in (x_n, x_n+h).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use the fact that  $y'(x_n) = f(x_n, y(x_n))$ and obtain the following two expressions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    " y(x_n+h) &= y(x_n) + h f(x_n,y(x_n)) + d_{n+1},  & \\text{the equation above} \\\\ \n",
    " y_{n+1} &= y_n + h f(x_n, y_n), & \\text{Euler's method}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We subtract the second from the first, use that $e_{n} = y(x_n)-y_n$, and finally use Result 3 in *Preliminaries*, section 5.\n",
    "This yields the expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "e_{n+1} = e_n + h \\big( f(x_n, y(x_n)) - f(x_n, y_n) \\big) + d_{n+1}\n",
    "          = e_n + h f_y(x_n, \\eta) e_n + d_{n+1},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where  $f_y = \\frac{\\partial f}{\\partial y}$, and $\\eta$ is some value between $y_n$ and $y(x_n)$. \n",
    "We now take the absolute value on each side, and apply the triangle inequality:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "|e_{n+1}| = |e_n + h f_y(x_n, \\eta) e_n + d_{n+1}| \\le  |e_n| + h |f_y(x_n, \\eta)|| e_n| + |d_{n+1}|.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume now that there exist positive constants $D$ and $L$ satisfying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "|f_y(x,y)| \\leq L \\qquad \\text{and} \\qquad |y''(x)| \\leq 2D\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for all values of $x$, $y$. From the inequality above we get that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "|e_{n+1}| \\le (1+hL)|e_n| + Dh^2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $y_0=y(x_0)$ we get $e_0=0$. The inequality above therefore results in\n",
    "the following estimates for the global errors:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "|e_1| &\\leq Dh^2 \\\\ \n",
    "|e_2| & \\leq (1+hL)|e_1| + Dh^2 \\leq \\big((1+hL)+1\\big) Dh^2 \\\\ \n",
    "|e_3| &\\leq (1+hL)|e_2|+ Dh^2 \\leq \\big((1+hL)^2 + (1+hL) + 1\\big) Dh^2 \\\\ \n",
    "& \\vdots \\\\ \n",
    "|e_N| & \\leq (1+hL)|e_{N+1}|+ Dh^2 \\leq \\sum_{n=0}^{N-1} (1+hL)^n Dh^2\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now apply two well known results: \n",
    "* The sum of a truncated geometric series: \n",
    "\n",
    "  * $\\displaystyle \\sum_{n=0}^{N-1}r^n = \\frac{r^N-1}{r-1}$ for $r\\in \\mathbb{R}$. \n",
    "\n",
    "\n",
    "* The series of the exponential: \n",
    "\n",
    "  * $\\displaystyle e^x = 1+x+ \\frac{1}{2}x^2 + \\dotsm = 1+x+ \\sum_{n=2}^{\\infty}\\frac{x^n}{n!}$ \n",
    "\n",
    "  which proves that $1+x < e^x$ whenever $x>0$. \n",
    "\n",
    "Using these results, we obtain that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sum_{n=0}^{N-1} (1+hL)^n = \\frac{(1+hL)^N-1}{(1+hL)-1}\n",
    "< \\frac{(e^{hL})^N-1}{hL} = \\frac{e^{hLN}-1}{hL}\n",
    "= \\frac{e^{L(x_{end}-x_0)}-1}{hL},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the last equality holds because $(x_{end}-x_0)=hN$. \n",
    "Finally, we plug this into the inequality for $|e_{N}|$ above,\n",
    "and we see that we have proved the the following upper bound for the global:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "|y(x_{end}) - y_N| = |e_N| \\leq \\frac{e^{L(x_{end}-x_0)}-1}{L} D h =  C h,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the constant $C=\\frac{e^{L(x_{end}-x_0)}-1}{L} D$ depends on the length of the integration interval $x_{end}-x_0$, of certain properties of the equation ($L$ and $D$), but *not* on the step size $h$.\n",
    "\n",
    "The numerical solution converges to the exact solution since"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\lim_{N\\rightarrow \\infty} |e_N| = 0.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the step size is reduced by a factor of 0.5, so will the error.\n",
    "This is in agreement with the previous numerical result. \n",
    "\n",
    "**Remark:**\n",
    "Following the proof of the error estimate for Euler's method,\n",
    "we see that a local truncation error of size $h^2$ leads\n",
    "to a final, global error of size $h$.\n",
    "Intuitively, this is because we need to take roughly $1/h$ steps\n",
    "in order to reach the point $x_{end}$,\n",
    "although a precise proof is quite a bit more complicated than that, as we have seen.\n",
    "However, what this also should mean is that a method\n",
    "with a truncation order of size $h^{p+1}$ should lead to a global error of $h^p$.\n",
    "The results of the next section show that, under certain\n",
    "conditions, this is indeed the case.\n",
    "\n",
    "\n",
    "## A general convergence result\n",
    "\n",
    "\n",
    "\n",
    "A one-step method applied to a system of ODEs $\\mb{y}'(x)=\\mb{f}(x,\\mb{y}(x))$ can be written in the generic form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mb{y}_{n+1} = \\mb{y}_n + h \\mb{\\Phi}(x_n, \\mb{y}_n; h),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the *increment function* $\\mb{\\Phi}$ typically depends on the function $\\mb{f}$ and some parameters defining the method.\n",
    "\n",
    "**Definition: Order of a method.**\n",
    "\n",
    "A method is of order $p > 0$ if there is a constant $C > 0$\n",
    "such that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\|\\mb{e}_N\\| = \\|\\mb{y}(x_{end})-\\mb{y}_N\\| \\leq C h^p,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $N$ is the number of steps taken to reach $x_{end}$ using the step size $h=(x_{end}-x_0)/N$.\n",
    "\n",
    "\n",
    "\n",
    "The local truncation error $\\mb{d}_{n+1}$ of such a method is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mb{d}_{n+1} = \\mb{y}(x_{n+1}) - \\left (\\mb{y}(x_n) + h \\mb{\\Phi}(x_n, \\mb{y}(x_n); h)\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the absolute values in the above proof with norms (*Preliminaries*, section 1), and the\n",
    "argument above can be used to prove the following: \n",
    "\n",
    "**Theorem: Convergence of one-step methods.**\n",
    "\n",
    "Assume that there exist  positive constants $M$ and $D$ such that the increment function satisfies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\| \\mb{\\Phi}(x,\\mb{y};h) - \\mb{\\Phi}(x,\\mb{z};h) \\| \\leq M \\| \\mb{y}-\\mb{z} \\|\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the local truncation error satisfies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\| \\mb{y}(x+h) - \\left (\\mb{y}(x) + h \\mb{\\Phi}(x, \\mb{y}(x), h)\\right) \\| \\leq Dh^{p+1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for all $x$, $\\mb{y}$ and $\\mb{z}$ in a neighbourhood of the solution. In that case, the global error satisfies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\|\\mb{e}_N\\| = \\|\\mb{y}(x_{end})-\\mb{y}_N\\| \\leq C h^p, \\qquad\\text{ with } C =\n",
    "\\frac{e^{M(x_{end}-x_0)}-1}{M}D.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be proved that the first of these conditions is satisfied for all the methods that will be considered here,\n",
    "provided that the function $\\mb{f}$ is continuously differentiable.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Heun's method\n",
    "\n",
    "We will now discuss a first, improved alternative to Euler's method:\n",
    "\n",
    "Assume that we want to solve an"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mb{y}'(x) = \\mb{f}(x,\\mb{y}(x)).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its exact solution can be written in integral form as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mb{y}(x_n + h) =\n",
    "\\mb{y}(x_n) + \\int_{x_n}^{n_n + h} \\mb{y}'(x)\\,dx\n",
    "=\n",
    "\\mb{y}(x_n) + \\int_{x_n}^{x_{n}+h} \\mb{f}(x,\\mb{y}(x)) dx.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now replace the integral on the right hand side\n",
    "by a numerical approximation using the trapezoidal rule:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mb{y}(x_n+h) \\approx \\mb{y}(x_n) + \\frac{h}{2}\n",
    "\\big(\\mb{f}(x_n, \\mb{y}(x_n)) + \\mb{f}(x_{n+1},\\mb{y}(x_{n+1})\\big).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we replace $\\mb{y}(x_n)$ and $\\mb{y}(x_{n+1})$ by the approximations\n",
    "$\\mb{y}_n$ and $\\mb{y}_{n+1}$. The resulting method is the *trapezoidal rule for ODEs*, given by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mb{y}_{n+1} = \\mb{y}_{n} + \\frac{h}{2} \\big( \\mb{f}(x_n,\\mb{y}_n) + \\mb{f}(x_{n+1},\\mb{y}_{n+1})\\big).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of an *implicit* method.\n",
    "The numerical approximation $\\mb{y}_{n+1}$ appears on both\n",
    "sides of this equation as is therefore only implicitly given:\n",
    "If $x_n,\\mb{y}_n$ is known, a nonlinear equation has to be solved\n",
    "in order to find $\\mb{y}_{n+1}$, and this has to be done for each step.\n",
    "There are important applications where this actually makes sense,\n",
    "which we will discuss in a later lecture in the context of *stiff ODEs*.\n",
    "\n",
    "However, for the moment we want to avoid this additional complication\n",
    "and thus replace the $\\mb{y}_{n+1}$ on the right hand side by some\n",
    "approximation. One natural possibility here is to apply one step\n",
    "of Euler's method.\n",
    "This results in [Heun's method](https://wiki.math.ntnu.no/tma4100/tema/differentialequations?&#numeriske_losninger):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "   \\mb{u}_{n+1} &= \\mb{y}_n + h \\mb{f}(x_n, \\mb{y}_n), \\\\ \n",
    "   \\mb{y}_{n+1} &= \\mb{y}_n + \\frac{h}{2} \\big(\\mb{f}(x_n,\\mb{y}_n) + \\mb{f}(x_{n+1},\\mb{u}_{n+1}) \\big).\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method is commonly written in the form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "  \\mb{k}_1 &= \\mb{f}(x_n, \\mb{y}_n), \\\\ \n",
    "  \\mb{k}_2 &= \\mb{f}(x_n+h, \\mb{y}_n+h \\mb{k}_1), \\\\ \n",
    "  \\mb{y}_{n+1} &= \\mb{y}_n + \\frac{h}{2}(\\mb{k}_1 + \\mb{k}_2).\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The increment function for this method is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mb{\\Phi}(x,\\mb{y};h) = \\frac{1}{2}\\big(\\mb{f}(x,\\mb{y})+\\mb{f}(x+h,\\mb{y}+h\\mb{f}(x,\\mb{y}))\\big).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "One step of Heuns's method is implemented as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def heun(f, x, y, h):\n",
    "    # One step of Heun's method\n",
    "    k1 = f(x, y)\n",
    "    k2 = f(x+h, y+h*k1)\n",
    "    y_next = y + 0.5*h*(k1+k2)\n",
    "    x_next = x + h\n",
    "    return x_next, y_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Numerical example 5:**\n",
    "Let us compare the numerical solution from Euler's and Heun's methods on the scalar test \n",
    "problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y' = -2xy, \\qquad y(0)=1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with the exact solution\n",
    "$y(x) = e^{-x^2}$ on the interval $[0,1]$.\n",
    "Use  $h=0.1$ for Euler's method and $h=0.2$ for Heun's metode. Thus both require a total of 10\n",
    "function evaluations, and the total amount of computational work is comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Numerical experiment 5\n",
    "\n",
    "def f(x, y):            # The right hand side of the ODE\n",
    "    return -2*x*y\n",
    "\n",
    "def y_exact(x):         # The exact solution\n",
    "    return exp(-x**2)\n",
    "\n",
    "h = 0.1                 # The stepsize\n",
    "x0, xend = 0, 1         # Integration interval             \n",
    "y0 = 1                  # Initial value\n",
    "\n",
    "# Solve the equations\n",
    "xn_euler, yn_euler = ode_solver(f, x0, xend, y0, h, method=euler)\n",
    "xn_heun, yn_heun = ode_solver(f, x0, xend, y0, 2*h, method=heun)     \n",
    "\n",
    "# Plot the solution\n",
    "x = linspace(x0, xend, 101)\n",
    "plot(xn_euler, yn_euler, 'o') \n",
    "plot(xn_heun, yn_heun, 'd')\n",
    "plot(x, y_exact(x))\n",
    "legend(['Euler','Heun','Exact']);\n",
    "xlabel('x')\n",
    "ylabel('y');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The errors of the two approximations are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the error of the two methods\n",
    "semilogy(xn_euler, abs(y_exact(xn_euler)- yn_euler), 'o');\n",
    "semilogy(xn_heun, abs(y_exact(xn_heun)- yn_heun), 'd');\n",
    "xlabel('x')\n",
    "ylabel('Error')\n",
    "legend(['Euler', 'Heun'],loc=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us finally compare the error  at $x_{end}$ when the two methods are applied to our test problem,\n",
    " for different values of $h$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print the error as a function of h. \n",
    "print('Error in Euler and Heun\\n')\n",
    "print('h           Euler       Heun')\n",
    "print('---------------------------------')\n",
    "for n in range(10):\n",
    "    x_euler, y_euler = ode_solver(f, x0, xend, y0, h, method=euler)\n",
    "    x_heun, y_heun = ode_solver(f, x0, xend, y0, 2*h, method=heun)\n",
    "    error_euler = abs(y_exact(xend)-y_euler[-1])\n",
    "    error_heun = abs(y_exact(xend)-y_heun[-1])\n",
    "    print(format('{:.3e}   {:.3e}   {:.3e}'.format( h, error_euler, error_heun)))\n",
    "    h = 0.5*h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, Heun's method is significantly more accurate than Euler's method, even when the \n",
    "number of function evaluations are the same. Further, we notice that the error in Heun's method is reduced by a factor of approximately 1/4 whenever the step size is reduced by a factor 1/2, indicating that the error $|y(x_{end}-y_N| \\approx Ch^2$, and the method is of order 2.  \n",
    "\n",
    "**Numerical example 6:**\n",
    "Solve the Lotka-Volterra equation from Numerical example 2 by Euler's and Heun's methods, again using twice as many steps for Euler's method than for Heun's method. \n",
    "* Use $h=0.01$ for Euler's method and $h=0.02$ for Heun's method. \n",
    "\n",
    "* Use $h=0.1$ for Euler's method and $h=0.2$ for Heun's method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Numerical example 6\n",
    "\n",
    "def lotka_volterra(x, y):       # The Lotka-Volterra equation\n",
    "    alpha, beta, delta, gamma = 2, 1, 0.5, 1        # Parameters\n",
    "    dy = array([alpha*y[0]-beta*y[0]*y[1],  \n",
    "                delta*y[0]*y[1]-gamma*y[1]])\n",
    "    return dy\n",
    "\n",
    "x0, xend = 0, 20\n",
    "y0 = array([2, 0.5])\n",
    "h = 0.01\n",
    "\n",
    "x_euler, y_euler = ode_solver(lotka_volterra, x0, xend, y0, h, method=euler)\n",
    "x_heun, y_heun = ode_solver(lotka_volterra, x0, xend, y0, 2*h, method=heun)\n",
    "\n",
    "plot(x_euler,y_euler)\n",
    "plot(x_heun, y_heun, '--')\n",
    "xlabel('x')\n",
    "title('Lotka-Volterra ligningen')\n",
    "legend(['y1 (Euler)','y2', 'y1 (Heun)', 'y2'],loc=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Numerical exercises:**\n",
    "1. Solve Van der Pol's equation by use of Heun's method. Experiment with different choices of the step size $h$ and compare with the results from Numerical experiment 3. \n",
    "\n",
    "2. Implement the [classical Runge - Kutta method](https://en.wikipedia.org/wiki/Runge–Kutta_methods#The_Runge–Kutta_method) and verify numerically that the order of the method is 4. The method is given by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "   \\mb{k}_1 &= \\mb{f}(x_n, \\mb{y}_n)\\\\ \n",
    "   \\mb{k}_2 &= \\mb{f}\\left(x_n+\\frac{h}{2}, \\mb{y}_n + \\frac{h}{2}\\mb{k}_1\\right) \\\\ \n",
    "   \\mb{k}_3 &= \\mb{f}\\left(x_n+\\frac{h}{2}, \\mb{y}_n + \\frac{h}{2}\\mb{k}_2\\right) \\\\ \n",
    "   \\mb{k}_4 &= \\mb{f}(x_n+h, \\mb{y}_n + h\\mb{k}_3)\\\\ \n",
    "   \\mb{y}_{n+1} &= \\mb{y}_n + \\frac{h}{6}(\\mb{k}_1 + 2\\mb{k}_2 + 2\\mb{k}_3 + \\mb{k}_4).\n",
    "   \\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convergence properties of Heun's method\n",
    "\n",
    "To prove convergence and to find the order of a method two things are needed: \n",
    "* the local truncation error, expressed as a power series in the step size $h$\n",
    "\n",
    "* the condition  $\\| \\mb{\\Phi}(x,\\mb{y};h) - \\mb{\\Phi}(x,\\mb{z};h) \\| \\leq M \\| \\mb{y}-\\mb{z} \\|$\n",
    "\n",
    "The local truncation error is found by comparing Taylor series expansions of the exact and the numerical solutions starting from the same point. In practice, this is not trivial. For simplicity, we will here do this only for a scalar equation $y'(x)=f(x,y(x))$. The result is valid for systems as well.\n",
    "\n",
    "In the following, we will use the notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f_x = \\frac{\\partial f}{\\partial x}, \\qquad f_y = \\frac{\\partial f}{\\partial y}, \n",
    "\\qquad f_{xx} = \\frac{\\partial^2 f}{\\partial x^2} \\qquad  f_{xy} \n",
    "= \\frac{\\partial^2f}{\\partial x\\partial y} \\qquad\\text{etc.}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further, we will surpress the arguments of the function $f$ and its derivatives. So $f$ is to be understood as $f(x,y(x))$ although it is not explicitly written. \n",
    "\n",
    "\n",
    "The Taylor expansion of the exact solution $y(x+h)$ is given by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y(x+h)=y(x)+hy'(x) + \\frac{h^2}{2}y''(x) + \\frac{h^3}{6}y'''(x) + \\ldots.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Higher derivatives of $y(x)$ can be expressed in terms of the function $f$ by using the chain rule and the product rule for differentiation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "    y'(x) &= f, \\\\ \n",
    "    y''(x) &= f_x  + f_y y' = f_x + f_y f,\\\\ \n",
    "    y'''(x) &= f_{xx} + f_{xy} y' + f_{yx}f + f_{yy}y'f + f_yf_x +f_y f_y y' \n",
    "             = f_{xx}+2f_{xy}f+f_{yy}f^2 +f_yf_x+ (f_y)^2f.\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then find the series of the exact and the numerical solution around $x_0,y_0$ (any other point will do equally well). From the discussion above, the series for the exact solution becomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y(x_0+h) = y_0 + hf + \\frac{h^2}{2}(f_x + f_y f) +\n",
    "\\frac{h^3}{6}(f_{xx}+2f_{xy}f+f_{yy}f^2 + f_yf_x+ (f_y)^2f\n",
    ") + \\ldots,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $f$ and all its derivatives are evaluated in $(x_0,y_0)$. For the numerical solution we get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "  k_1 &= f(x_0,y_0) = f, \\\\ \n",
    "  k_2 &= f(x_0+h, y_0+hk_1) \\\\ \n",
    "      & = f + hf_x + f_yhk_1 + \\frac{1}{2}f_{xx}h^2 + f_{xy}hhk_1 + \\frac{1}{2}f_{yy}h^2 k_1^2 \n",
    "       + \\ldots \\\\ \n",
    "      &= f + h(f_x + f_yf) + \\frac{h^2}{2}(f_{xx} + 2f_{xy}f + f_{yy}f^2) + \\ldots, \\\\ \n",
    "  y_1 &= y_0 + \\frac{h}{2}(k_1 + k_2) = y_0 + \\frac{h}{2}\\Bigl(f + f + h(f_x + f_yf) + \\frac{h^2}{2}(f_{xx} + 2f_{xy}f + f_{yy}f^2) + \\ldots\\Bigr) \\\\ \n",
    "      &= y_0 + hf + \\frac{h^2}{2}(f_x+f_yf)+ \\frac{h^3}{4}(f_{xx} + 2f_{xy}f + f_{yy}f^2)  + \\ldots,\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the local truncation error will be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "d_{1} = y(x_0+h)-y_1 = \\frac{h^3}{12}(-f_{xx}-2f_{xy}f-f_{yy}f^2 + 2f_yf_x + 2(f_y)^2f) + \\ldots.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first nonzero term in the local truncation error series is called *the principal error term*. For $h$ sufficiently small this is the term dominating the error, and this fact will be used later. \n",
    "\n",
    "Although the series has been developed around the initial point, series around $x_n,y(x_n)$ will give \n",
    "similar results, and it is possible to conclude that, given sufficient differentiability of $f$, there is a constant $D$ such that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "|d_n| \\leq Dh^3.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further, we have to prove the condition on the increment function $\\Phi(x,y)$. For $f$ differentiable, there is for all $y,z$ some $\\xi$ between $x$ and $y$ such that $f(x,y)-f(x,z) = f_y(x,\\xi)(y-z)$. Let $L$ be a constant such that $|f_y| \\le L$, and for all $x$, $y$, $z$ of interest we get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "|f(x,y)-f(x,z)| \\leq L |y-z|.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The increment function for Heun's method is given by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\Phi(x,y) = \\frac{1}{2}\\bigl(f(x,y)+f(x+h,y+hf(x,y))\\bigr). \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By repeated use of the condition above and the triangle inequalitiy for absolute values we get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "|\\Phi(x,y)-\\Phi(x,z)| &= \\frac{1}{2}|f(x,y)+f(x+h,y+hf(x,y))-f(x,z)-hf(x+h,z+hf(x,z))| \\\\ \n",
    "&\\leq \\frac{1}{2}\\big(|f(x,y)-f(x,z)|+|f(x+h,y+hf(x,y))-f(x+h,z+hf(x,z))| \\big) \\\\ \n",
    "&\\leq \\frac{1}{2}\\big(L|y-z| + L|y+hf(x,y)-z-hf(x,z)| \\big) \\\\ \n",
    "&\\leq \\frac{1}{2}\\big(2L|y-z|+hL^2|y-z|\\big) \\\\ \n",
    "& = \\Bigl(L+\\frac{h}{2}L^2\\Bigr)|y-z|.\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that the step size $h$ is bounded above by some $H$, we can conclude that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "|\\Phi(x,y)-\\Phi(x,z)| \\leq M|y-z|, \\qquad M=L+\\frac{H}{2}L^2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion: Heun's method is convergent of order 2.  \n",
    "\n",
    "# Error estimation and step size control\n",
    "\n",
    "To control the global error $y(x_n)-y_n$ is notoriously difficult, and far beyond what will \n",
    "be discussed in this course. To control the local error in each step and adjust the step size \n",
    "accordingly is rather straightforward, as we will see. \n",
    "\n",
    "## Error estimation\n",
    "Given two methods, one of order $p$ and the other of order $p+1$ or higher. Assume we have \n",
    "reached a point $(x_n,\\mb{y}_n)$. One step forward with each of these methods can be written as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*} \n",
    "  \\mb{y}_{n+1} &= \\mb{y}_n + h \\mb{\\Phi}(x_n, \\mb{y}_n; h), && \\text{order $p$}, \\\\ \n",
    "  \\widehat{\\mb{y}}_{n+1} &= \\mb{y}_n + h \\widehat{\\mb{\\Phi}}(x_n, \\mb{y}_n; h), && \\text{order $p+1$ or more}. \\\\ \n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\mb{y}(x_{n+1};x_n,\\mb{y}_n)$ be the exact solution of the ODE through $(x_n,\\mb{y}_n)$. \n",
    "We would like to find an estimate for *the local error* $\\mb{l}_{n+1}$, that is, the error in one step starting from  $(x_n, \\mb{y}_n)$,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mb{l}_{n+1} = \\mb{y}(x_{n+1};x_n,\\mb{y}_n) - \\mb{y}_{n+1}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we already have seen, the local error is found by finding the power series in $h$ of the exact \n",
    "and the numerical solution. The local error is of order $p$ if the lowest order terms in the series where the exact and the numerical solution differ is of order $p+1$. So the local errors of the two methods are"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\mb{y}(x_{n+1};x_n,\\mb{y}_n) - \\mb{y}_{n+1} &= \\mb{\\Psi}(x_n,y_n)h^{p+1}  +\\dotsc, \\\\ \n",
    "\\mb{y}(x_{n+1};x_n,\\mb{y}_n) - \\widehat{\\mb{y}}_{n+1} &= \\hphantom{\\mb{\\Psi}(x_n,y_n)h^{p+1} } + \\dotsc,\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\Psi(x_n,y_n)$ is a term consisting of method parameters and differentials of $\\mb{f}$ and \n",
    "$\\dotsc$ contains all the terms of the series of order $p+2$ or higher. Taking the difference gives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\widehat{\\mb{y}}_{n+1} - \\mb{y}_{n+1} = \\mb{\\Psi}(x_n,\\mb{y}_n)h^{p+1} + \\ldots.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume now that $h$ is small, such that the *principal error term* $\\mb{\\Psi(x_n,y_n)}h^{p+1}$ dominates the error series. Then a reasonable approximation to the unknown local error $\\mb{l}_{n+1}$ is the *local error estimate* $\\mb{le}_{n+1}$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mb{le}_{n+1} = \\widehat{\\mb{y}}_{n+1} - \\mb{y}_{n+1} \\approx \\mb{y}(x_{n+1};x_n,\\mb{y}_n) - \\mb{y}_{n+1}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 4:**\n",
    "Apply Euler's method of order 1 and Heun's method of order 2 with $h=0.1$ to the equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y' = -2xy, \\qquad y(0)=1.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this to find an approximation to the error after one step. \n",
    "\n",
    "Euler's method:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y_1 = 1.0 - 0.1\\cdot 2 \\cdot 0 \\cdot 1.0 = 1.0.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heun's method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    " k_1 &= -2\\cdot 0.0 \\cdot 1.0 = 0.0,  \\\\ \n",
    " k_2 &= -2\\cdot 0.1\\cdot (1+0.0) = -0.2, \\\\ \n",
    " \\widehat{y}_1&  = 1.0 + \\frac{0.1}{2}\\cdot(0.0 - 0.2) = 0.99.\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error estimate and the local error are respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "le_{1} = \\widehat{y}_1 - y_1 = -10^{-2}, \\qquad\n",
    "   l_1 = y(0.1)-y_1 = e^{-0.1^2}-1.0 =  -0.995 \\cdot 10^{-2}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in this case the error estimate is a quite decent approximation to the actual local error. \n",
    "\n",
    "## Stepsize control\n",
    "The next step is to control the local error, that is, choose the step size so that $\\|\\mb{le}_{n+1}\\| \\leq \\text{Tol}$ for some given tolerance Tol, and for some chosen norm $\\|\\cdot\\|$. \n",
    "\n",
    "Essentially: \n",
    "\n",
    "Given $x_n, \\mb{y}_n$ and a step size $h_n$. \n",
    "* Do one step with the method of choice, and find an error estimate $\\mb{le}_{n+1}$. \n",
    "\n",
    "* if  $\\|\\mb{le}\\|_{n+1} < \\text{Tol}$\n",
    "\n",
    "    * Accept the solution $x_{n+1}, \\mb{y}_{n+1}$.\n",
    "\n",
    "    * If possible, increase the step size for the next step.\n",
    "\n",
    "\n",
    "* else\n",
    "\n",
    "    * Repeat the step from $(x_n,\\mb{y}_n)$ with a reduced step size $h_{n}$.\n",
    "\n",
    "\n",
    "In both cases, the step size will change. But how? \n",
    "\n",
    "From the discussion above, we have that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\| \\mb{le}_{n+1} \\| \\approx D  h_{n}^{p+1}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\mb{le}_{n+1}$ is the error estimate we can compute, $D$ is some unknown quantity, which we assume almost constant from one step to the next. What we want is a step size $h_{new}$ such that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Tol} \\approx D h_{new}^{p+1}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these two approximations we get:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\text{Tol}}{\\|\\mb{le}_{n+1}\\|} \\approx \\left(\\frac{h_{new}}{h_n}\\right)^{p+1}\n",
    "\\qquad \\Rightarrow \\qquad\n",
    "h_{new} \\approx \\left( \\frac{\\text{Tol}}{\\|\\mb{le}_{n+1}\\|} \\right)^{\\frac{1}{p+1}} h_{n}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is, if the current step $h_n$ was rejected, we try a new step $h_{new}$\n",
    "with this approximation.\n",
    "However, it is still possible that this new step will be rejected as well.\n",
    "To avoid too many rejected steps, it is therefore common to be a bit restrictive when choosing the new \n",
    "step size, so the following is used in practice:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "h_{new} = P\\cdot \\left( \\frac{\\text{Tol}}{\\|\\mb{le}_{n+1}\\|} \\right)^{\\frac{1}{p+1}} h_{n}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the *pessimist factor* $P<1$ is some constant, normally chosen between 0.5 and 0.95.\n",
    "\n",
    "## Implementation\n",
    "We have all the bits and pieces for constructing an adaptive ODE solver based on Euler's and Heuns's methods. There are still some practical aspects to consider: \n",
    "\n",
    "* The combination of the two methods, implemented in `heun_euler` can be written as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "      \\mb{k}_1 &= \\mb{f}(x_n, \\mb{y}_n), \\\\ \n",
    "      \\mb{k}_2 &= \\mb{f}(x_n+h, \\mb{y}_n+h \\mb{k}_1), \\\\ \n",
    "      \\mb{y}_{n+1} &= \\mb{y}_n + h \\mb{k}_1, && \\text{Euler} \\\\ \n",
    "      \\widehat{\\mb{y}}_{n+1} &= \\mb{y}_n + \\frac{h}{2}(\\mb{k}_1 + \\mb{k}_2), && \\text{Heun} \\\\ \n",
    "      \\mb{le}_{n+1} &= \\|\\widehat{\\mb{y}}_{n+1} - \\mb{y}_{n+1}\\| = \\frac{h}{2}\\|\\mb{k}_2-\\mb{k}_1 \\|.\n",
    "    \\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Even if the error estimate is derived for the lower order method, in this case Euler's method, it is common to advance the solution with the higher order method, since the additional accuracy is for free. \n",
    "\n",
    "* Adjust the last step to be able to terminate the solutions exactly in $x_{end}$. \n",
    "\n",
    "* To avoid infinite loops, add some stopping criteria. In the code below, there is a maximum number of allowed steps (rejected or accepted). \n",
    "\n",
    "* The main driver `ode_adaptive` is written to make it simple to test other pairs of methods. This is also the reason why the function `heun_euler` returns the order of the lowest order method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def heun_euler(f, x, y, h):\n",
    "    '''\n",
    "    One step with the pair Heun/Euler\n",
    "    Input: the function f, the present state xn and yn  and the stepsize h\n",
    "    Output: the solution x and y in the next step, error estimate, and the\n",
    "            order p of Eulers method (the lowest order) \n",
    "    '''\n",
    "    \n",
    "    k1 = f(x, y)\n",
    "    k2 = f(x+h, y+h*k1)\n",
    "    y_next = y + 0.5*h*(k1+k2)      # Heuns metode (local extrapolation)\n",
    "    x_next = x + h\n",
    "    error_estimate = 0.5*h*norm(k2-k1)   # The 2-norm or the error estimate\n",
    "    p = 1\n",
    "    return x_next, y_next, error_estimate, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ode_adaptive(f, x0, xend, y0, h0, tol = 1.e-6, method=heun_euler):\n",
    "    '''\n",
    "    Adaptive solver for ODEs\n",
    "       y' = f(x,y), y(x0)=y0\n",
    "    \n",
    "    Input: the function f, x0, xend, and the initial value y0\n",
    "           intial stepsize h, the tolerance tol, \n",
    "           and a function (method) implementing one step of a pair.\n",
    "    Output: Array with x- and y- values.\n",
    "    '''\n",
    "    \n",
    "    y_num = array([y0])    # Array for the solutions y\n",
    "    x_num = array([x0])    # Array for the x-values\n",
    "\n",
    "    xn = x0                # Running values for  x, y and the stepsize h\n",
    "    yn = y0 \n",
    "    h = h0\n",
    "    Maxcall = 100000        # Maximum allowed calls of method\n",
    "    ncall = 0\n",
    "    \n",
    "    # Main loop\n",
    "    while xn < xend - 1.e-10:               # Buffer for truncation error\n",
    "        # Adjust the stepsize for the last step\n",
    "        if xn + h > xend:                   \n",
    "            h = xend - xn \n",
    "        \n",
    "        # Perform one step with the chosen mehtod\n",
    "        x_try, y_try, error_estimate, p = method(f, xn, yn, h)\n",
    "        ncall = ncall + 1\n",
    "        \n",
    "        if error_estimate <= tol:   \n",
    "            # Solution accepted, update x and y\n",
    "            xn = x_try    \n",
    "            yn = y_try\n",
    "            # Store the solutions \n",
    "            y_num = concatenate((y_num, array([yn])))\n",
    "            x_num = append(x_num, xn)\n",
    "        \n",
    "        # else: The step is rejected and nothing is updated. \n",
    "        \n",
    "        # Adjust the stepsize\n",
    "        h = 0.8*(tol/error_estimate)**(1/(p+1))*h\n",
    "        \n",
    "        # Stop with a warning in the case of max calls to method\n",
    "        if ncall > Maxcall:\n",
    "            print('Maximum number of method calls')\n",
    "            return x_num, y_num\n",
    "\n",
    "    # Some diagnostic output\n",
    "    print('Number of accepted steps = ', len(x_num)-1)\n",
    "    print('Number of rejected steps = ', ncall - len(x_num)+1)\n",
    "    return x_num, y_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Numerical example 7:**\n",
    "Apply the code on the test equation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y' = -2xy, \\qquad y(0)=1.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Numerical example 7\n",
    "def f(x, y):\n",
    "    return -2*x*y\n",
    "\n",
    "def y_exact(x):\n",
    "    return exp(-x**2)\n",
    "\n",
    "h0 = 100\n",
    "x0, xend = 0, 1\n",
    "y0 = 1\n",
    "\n",
    "x_num, y_num = ode_adaptive(f, x0, xend, y0, h0, tol=1.e-3)\n",
    "\n",
    "plot(x_num, y_num, '.-', x_num, y_exact(x_num))\n",
    "title('Adaptive Heun-Euler')\n",
    "xlabel('x')\n",
    "ylabel('y')\n",
    "legend(['Numerical', 'Exact']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error $|y(x_n)-y_n|$ is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the error from the adaptive method\n",
    "error = abs(y_exact(x_num) - y_num)\n",
    "semilogy(x_num, error, '.-')\n",
    "title('Error in Heun-Euler for dy/dt=-2xy')\n",
    "xlabel('x');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the step size will change like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the step size sequence\n",
    "h_n = diff(x_num)            # array with the stepsizes h_n = x_{n+1} \n",
    "x_n = x_num[0:-1]            # array with x_num[n], n=0..N-1\n",
    "semilogy(x_n, h_n, '.-')\n",
    "xlabel('x')\n",
    "ylabel('h')\n",
    "title('Stepsize variations');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Numerical exercises:**\n",
    "1. Solve the Lotka-Volterra equation, use for instance $h_0=0.1$ and $\\text{Tol}=10^{-3}$. Notice also how the step size varies over the integration interval. \n",
    "\n",
    "2. Repeat the experiment using Van der Pol's equation. \n",
    "\n",
    "## Runge - Kutta methods\n",
    "Euler's and Heun's method are both\n",
    "examples of \\textit{explicit Runge-Kutta methods} (ERK). Such schemes\n",
    "are given by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:erk\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "  \\label{eq:erk} \\tag{1}\n",
    "  \\mb{k}_1 & = \\mb{f}(x_n,\\mb{y}_n), \\\\ \n",
    "  \\mb{k}_2 & = \\mb{f}(x_n+c_2h, \\mb{y}_n+ha_{21}\\mb{k}_1), \\nonumber \\\\ \n",
    "  \\mb{k}_3 & = \\mb{f}\\big(x_n+c_3h, \\mb{y}_n+h(a_{31}\\mb{k}_1 + a_{32}\\mb{k}_2)\\big), \\nonumber \\\\ \n",
    "      & \\vdots \\nonumber \\\\ \n",
    "  \\mb{k}_s &= \\mb{f}\\big(x_n+c_sh, \\mb{y}_n + h\\sum_{j=1}^{s-1}a_{sj}\\mb{k}_j \\big), \\nonumber \\\\ \n",
    "  \\mb{y}_{n+1} &= \\mb{y}_n + h\\sum_{i=1}^s b_i \\mb{k}_i, \\nonumber\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $c_i,\\; a_{ij}$ and $b_i$ are coefficients defining the\n",
    "method. We always require $c_i = \\sum_{j=1}^s a_{ij}$. \n",
    "Here, $s$ is the number of \\textit{stages}, or the number of function\n",
    "evaluations needed for each step. The vectors $\\mb{k}_i$ are called stage\n",
    "derivatives. Also implicit methods, like the trapezoidal rule,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mb{y}_{n+1} = \\mb{y}_n+\\frac{h}{2}\\big(\\mb{f}(x_n,\\mb{y}_n)+\\mb{f}(x_n+h,\\mb{y}_{n+1})\\big)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "can be written in a similar form,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "  \\mb{k}_1 &= \\mb{f}(x_n,\\mb{y}_n), \\\\ \n",
    "  \\mb{k}_2 &= \\mb{f}\\big(x_n+h,\\mb{y}_n+\\frac{h}{2}(\\mb{k}_1+\\mb{k}_2)\\big), \\\\ \n",
    "  \\mb{y}_{n+1} &= \\mb{y}_n+\\frac{h}{2}(\\mb{k}_1+\\mb{k}_2).\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, contrary to what is the case for explicit methods, a\n",
    "nonlinear system of equations has to be solved to find $\\mb{k}_2$.\n",
    "\n",
    "**Definition: Runge - Kutta methods.**\n",
    "\n",
    "An $s$-stage Runge-Kutta method is given by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "     \\mb{k}_i &= \\mb{f}\\big(x_n+c_ih,\\mb{y}_n+h\\sum_{j=1}^s a_{ij}\\mb{k}_j\\big), \\qquad i=1,2,\\cdots,s, \\\\ \n",
    "     \\mb{y}_{n+1} &= \\mb{y}_n + h\\sum_{i=1}^s b_i \\mb{k}_i.\n",
    "  \\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method is defined by its coefficients, which are given in a\n",
    "*Butcher tableau*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{array}{c|cccc}\n",
    "    c_1 & a_{11} & a_{12} & \\cdots & a_{1s} \\\\ \n",
    "    c_2 & a_{21} & a_{22} & \\cdots & a_{2s} \\\\ \n",
    "    \\vdots & \\vdots &&&\\vdots \\\\ \n",
    "    c_s & a_{s1} & a_{s2} & \\cdots & a_{ss} \\\\ \\hline\n",
    "        & b_1 & b_2 & \\cdots & b_s \n",
    "  \\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "c_i = \\sum_{j=1}^s a_{ij}, \\quad\n",
    "    i=1,\\cdots,s.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method is *explicit* if $a_{ij}=0$ whenever $j\\geq i$;\n",
    "  otherwise it is *implicit*.\n",
    "\n",
    "\n",
    "\n",
    "A Runge - Kutta methods with an error estimate are usually called *embedded Runge - Kutta methods* or *Runge - Kutta pairs*, and\n",
    "the coefficients can be written in a Butcher tableau as follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{array}{c|ccccl}\n",
    "    c_1 & a_{11} & a_{12} & \\cdots & a_{1s} \\\\ \n",
    "    c_2 & a_{21} & a_{22} & \\cdots & a_{2s} \\\\ \n",
    "    \\vdots & \\vdots &&&\\vdots \\\\ \n",
    "    c_s & a_{s1} & a_{s2} & \\cdots & a_{ss} \\\\ \\hline\n",
    "        & b_1 & b_2 & \\cdots & b_s  & \\qquad\\text{Order $p$}\\\\ \\hline\n",
    "        & \\widehat{b}_1 & \\widehat{b_2} & \\cdots & \\widehat{b}_s  & \\qquad\\text{Order $p+1$}\n",
    "   \\end{array}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error estimate is then given by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mb{le}_{n+1} = h\\sum_{i=1}^s (\\widehat{b}_i - b_i)\\mb{k}_i.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 5:**\n",
    "  The Butcher-tableaux for the methods presented so far are"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{array}{ccccccc}\n",
    "    \\displaystyle\n",
    "    \\begin{array}{c|c}\n",
    "      0 & 0 \\\\ \\hline & 1\n",
    "    \\end{array}\n",
    "    & \\qquad  &\n",
    "    \\displaystyle\n",
    "    \\begin{array}{c|cc}\n",
    "      0 & 0 & 0\\\\ 1 & 1 &0 \\\\ \\hline & \\frac{1}{2} & \\frac{1}{2} \n",
    "    \\end{array}\n",
    "    & \\qquad &\n",
    "    \\displaystyle\n",
    "    \\begin{array}{c|cc}\n",
    "      0 & 0 & 0 \\\\ 1 &  \\frac{1}{2} & \\frac{1}{2} \\\\ \\hline & \\frac{1}{2} & \\frac{1}{2}  \n",
    "    \\end{array} \\\\ \n",
    "    \\text{Euler} && \\text{Heun} && \\text{trapezoidal rule}\n",
    "  \\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the Heun-Euler pair can be written as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{array}{c|cc} 0 & & \\\\ 1 & 1 &   \\\\ \\hline & 1 & 0 \\\\ \\hline \\displaystyle & \\frac{1}{2} &  \\frac{1}{2} \n",
    " \\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A particular mention deserves also the classical Runge-Kutta method\n",
    "from a previous numerical exercise, which can be written as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{array}{c|cccc}\n",
    "      0 & 0 & 0 & 0 & 0\\\\ \\frac{1}{2} &  \\frac{1}{2} & 0 & 0 & 0\\\\ \\frac{1}{2} & 0 & \\frac{1}{2} & 0 & 0\\\\ 1 &  0 & 0 & 1 & 0 \\\\ \\hline & \\frac{1}{6} & \\frac{1}{3} & \\frac{1}{3} & \\frac{1}{6}  \n",
    "    \\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See this [list of Runge - Kutta methods](https://en.wikipedia.org/wiki/List_of_Runge–Kutta_methods) for more. \n",
    "\n",
    "### Order conditions for Runge - Kutta methods\n",
    "\n",
    "It can be proved that a Runge - Kutta method is of order $p$ if all the conditions up to and including $p$ in the table below are satisfied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{array}{c|c|c} \n",
    "   p  & \\text{conditions}  \\\\ \\hline \n",
    "   1 & \\sum b_i = 1 \\\\ \\hline \n",
    "  2 & \\sum b_i c_i = 1/2 \\\\ \\hline \n",
    "  3 & \\sum b_i c_i^2 = 1/3\\\\ \n",
    "   & \\sum b_i a_{ij} c_j = 1/6 \n",
    "  \\\\ \\hline \n",
    "  4 & \\sum b_ic_i^3=1/4 \\\\ \n",
    "  & \\sum b_i c_i a_{ij}c_j=1/8 \\\\ \n",
    "  & \\sum b_i a_{ij}c_j^2=1/12 \\\\ \n",
    "  & \\sum b_i a_{ij} a_{jk} c_k = 1/24 \\\\ \\hline \n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where sums are taken over all the indices from 1 to $s$. \n",
    "\n",
    "**Example 6:**\n",
    "Apply the conditions to Heun's method, for which $s=2$ and the Butcher tableau is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{array}{c|cc} \n",
    "c_1 & a_{11} & a_{12} \\\\ c_2 & a_{21} & a_{22} \\\\ \\hline & b_1 & b_2 \n",
    "\\end{array}\n",
    "=\n",
    "\\begin{array}{c|cc}\n",
    "0 & 0 & 0 \\\\ 1 & 1 & 0 \\\\ \\hline & \\frac{1}{2} & \\frac{1}{2} \n",
    "\\end{array}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The order conditions are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "p&=1 & b_1 + b_2 &= \\frac{1}{2} + \\frac{1}{2}= 1 && \\text{OK} \\\\ \\mbox{}\\\\ \\hline \\\\ \n",
    "p&=2 & b_1c_1 + b_2 c_2 &= \\frac{1}{2}\\cdot 0 + \\frac{1}{2}\\cdot 1 = \\frac{1}{2} && \\text{OK}\\\\ \\mbox{} \\\\ \\hline \\\\ \n",
    "p&=3 & b_1c_1^2 + b_2c_2^2 &= \\frac{1}{2}\\cdot 0^2 + \\frac{1}{2}\\cdot 1^2 = \\frac{1}{2} \\not= \\frac{1}{3} && \\text{Not satisfied} \\\\ \n",
    " &   & b_1(a_{11}c_1+a_{12}c_2)+b_2(a_{21}c_1+a_{22}c_2) &= \\frac{1}{2}(0\\cdot0 + 0\\cdot 1) + \\frac{1}{2}(1\\cdot 0 + 0\\cdot 1) \\\\ \n",
    "      &&&= 0 \\not=\\frac{1}{6} && \\text{Not satisfied}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method is of order 2. \n",
    "\n",
    "\n",
    "\n",
    "## A summary of some terms and definitions\n",
    "There have been quite a few definitions and different error terms in this\n",
    "note. So let us list some of them (not exclusive): \n",
    "\n",
    "**Definitions:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "&\\mb{y}'  = \\mb{f}(x, \\mb{y})&& \\text{the ODE} \\\\ \n",
    "&\\mb{y}(x\\,;\\,x^*,\\mb{y}^*), && \\text{the exact solution of the ODE through\n",
    "$(x^*,\\mb{y}^*)$} \\\\ \n",
    "&\\mb{y}(x) = \\mb{y}(x\\, ;\\, x_0, \\mb{y}_0), && \\text{the exact solution of\n",
    "$\\mb{y}'  = \\mb{f}(x, \\mb{y})$, $\\mb{y}(x_0) = \\mb{y}_0$} \\\\ \n",
    "&\\mb{y}_{n+1} = \\mb{y}_n + h\\mb{\\Phi}(x_n,y_n;h), && \\text{one step of the method} \n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\mb{\\Phi}$ represent a method of order $p$ and $\\hat{\\mb{\\Phi}}$ a method\n",
    "of order $p+1$.\n",
    "\n",
    "**Error concepts:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "& \\mb{d}_{n+1} = \\mb{y}(x_n+h\\,;\\,x_n, \\mb{y}(x_n)) - \\bigg(\\mb{y}(x_n) +\n",
    "h\\mb{\\Phi}(x_n,\\mb{y}(x_n);h)\\bigg), && \\text{the local truncation error} \\\\ \n",
    "& \\mb{l}_{n+1} = \\mb{y}(x_n+h\\,;\\,x_n, \\mb{y}_n) - \\bigg(\\mb{y}_n +\n",
    "h\\mb{\\Phi}(x_n,\\mb{y}_n;h)\\bigg), && \\text{the local  error} \\\\ \n",
    "& \\mb{le}_{n+1} = h\\bigg(\\hat{\\mb{\\Phi}}(x_n,\\mb{y}_n;h) - \\mb{\\Phi}(x_n,\\mb{y}_n;h) \\bigg), && \\text{the local error estimate}, \\quad \\mb{le}_{n+1} \\approx\n",
    "\\mb{l}_{n+1} \\\\ \n",
    "&\\mb{e}_{n} = \\mb{y}(x_n)-\\mb{y}_n && \\text{the global error} \n",
    "\\end{align*}\n",
    "$$"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
