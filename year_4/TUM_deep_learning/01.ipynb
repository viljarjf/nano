{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6488cc9c",
   "metadata": {},
   "source": [
    "# Deep Learning Lecture 1 - Tutorial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bee9151",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f76b4c3c",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "\n",
    "Draw a 200 samples each from these two distributions\n",
    "\n",
    "* A sample `s1` from a 2-D Gaussian with mean = `[1,1]` and covariance matrix cov = `[[1,0],[0,1]]`\n",
    "* A sample `s2` from a 2-D 1 Gaussian with mean = `[0,0]` and covariance matrix cov = `[[1,0.8],[0.8,1.0]]`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee154aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = np.random.multivariate_normal(mean=[1, 1], cov=[[1, 0], [0, 1]], size=(200))\n",
    "s2 = np.random.multivariate_normal(mean=[0, 0], cov=[[1, 0.8], [0.8, 1]], size=(200))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8b8fc06",
   "metadata": {},
   "source": [
    "\n",
    "## Step 2\n",
    "\n",
    "Prepare a scatter plot of both these sets of samples on the 2-D plane, with the markers having two different colors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a7ad7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(s1[:, 0], s1[:, 1])\n",
    "plt.scatter(s2[:, 0], s2[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0cb5e34",
   "metadata": {},
   "source": [
    "\n",
    "## Step 3\n",
    "\n",
    "As discussed in the lecture, the simples neural network is the \"Perceptron\" \n",
    "\n",
    "$$\n",
    "f(\\vec{x}; \\vec{w},b) = \\Phi(\\sum w_i x_i - b) = \\Phi(\\vec{w}\\cdot\\vec{x} - b)\n",
    "$$\n",
    "\n",
    "where $\\Phi$ is the heaviside step function.\n",
    "\n",
    "Write a function that implements the perceptron model and is able to evaluate a input sample for $w_1 = 0.2$, $w_2 = 0.4$ and $b = 0.7$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ddc09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_w = np.array([0.2, 0.4])\n",
    "_b = 0.7\n",
    "def preceptron_model(x: np.ndarray, w: np.ndarray = _w, b: float = _b):\n",
    "    return np.heaviside(np.inner(w, x) - b, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "573560b9",
   "metadata": {},
   "source": [
    "\n",
    "## Step 4\n",
    "\n",
    "Evaluate the function on a 2-D grid with 100 x 100 points and visualize what the function value looks like in the 2-D plane\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154e61cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.linspace(-3, 5, 100)\n",
    "x2 = np.linspace(-3, 5, 100)\n",
    "x1, x2 = np.meshgrid(x1, x2)\n",
    "x = np.stack((x1, x2), axis=-1)\n",
    "\n",
    "y_hat = preceptron_model(x)\n",
    "\n",
    "plt.figure()\n",
    "plt.contourf(x1, x2, y_hat)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2c3e81f",
   "metadata": {},
   "source": [
    "\n",
    "## Step 5\n",
    "\n",
    "As above, we often will want to evaluate a function on many points at once. Therefore it's useful to write the function in a way such that we can quickly do so. \n",
    "\n",
    "One way to to this is via \"matrix multiplication\" \n",
    "\n",
    "$$\n",
    "r = \\Phi(X w^T - b)\n",
    "$$\n",
    "\n",
    "where $X$ is a (N,2) matrix and $w^T$ is the transpose of the weight vector $\\vec{w}$ (i.e. column vector or (2,1) matrix)\n",
    "\n",
    "Write a function that can evaluate $N$ points in one go, by making use of this relationship\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b89919b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69be2520",
   "metadata": {},
   "source": [
    "\n",
    "## Step 6\n",
    "\n",
    "Sample 10,000 points in the 2-D input space uniformly between (-5,5) and evaluate those points using the perceptron model\n",
    "\n",
    "Additionally, re-add the scatter plot of the two Gaussian samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beca1a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.linspace(-5, 5, 100)\n",
    "x2 = np.linspace(-5, 5, 100)\n",
    "x1, x2 = np.meshgrid(x1, x2)\n",
    "x = np.stack((x1, x2), axis=-1)\n",
    "\n",
    "model = preceptron_model(x)\n",
    "\n",
    "plt.figure()\n",
    "plt.contourf(x1, x2, model)\n",
    "plt.scatter(s1[:, 0], s1[:, 1])\n",
    "plt.scatter(s2[:, 0], s2[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "edce7de4",
   "metadata": {},
   "source": [
    "\n",
    "## Step 7\n",
    "\n",
    "* Evaluate both Gaussian samples with the perceptron model.\n",
    "* Create a histogram for the output of the histogram of the two samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2a2a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_1 = preceptron_model(s1)\n",
    "y_hat_2 = preceptron_model(s2)\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(y_hat_1)\n",
    "plt.title(\"s1\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(y_hat_2)\n",
    "plt.title(\"s2\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c4cf07a0",
   "metadata": {},
   "source": [
    "\n",
    "## Step 8 \n",
    "\n",
    "Out of the 200 samples in `s1`, for how many events does the perceptron return 1 or zero respectively? \n",
    "\n",
    "How about for the sample `s2`?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfaced5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e02c0a70",
   "metadata": {},
   "source": [
    "\n",
    "## Step 9 \n",
    "\n",
    "Let's say the samples of s1 should of of type `1` and the samples of s2 are of type `0`. What's the accuracy (as a percentage) of the perceptron model in predicting the right type?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e1602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.count_nonzero(y_hat_1) / y_hat_1.size)\n",
    "print(1 - np.count_nonzero(y_hat_2) / y_hat_2.size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2969472",
   "metadata": {},
   "source": [
    "\n",
    "## Step 10\n",
    "\n",
    "This time we have you values for $w_1$, $w_2$, and $b$.. can you find values that are better at this prediction tasks?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76c1a04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
