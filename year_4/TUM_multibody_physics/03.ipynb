{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Finite size scaling\n",
    "\n",
    "In this exercise, we will determine the critical temperature and critical exponents of the\n",
    "Ising model.\n",
    "\n",
    "a) First, we need finite size data. Since generating the data takes some time, it is useful\n",
    "to save it to disk. Generate your own finite size data from last weeks program (which\n",
    "can take some time to get well converged results), and/or download finite size data\n",
    "provided on the GitLab page. Inspect generate_data.py to find out how the data\n",
    "is structured and how to load the data. Plot the specific heat CV and magnetic\n",
    "susceptibility χ."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall: \n",
    "$$ C_v = \\frac{1}{k_BT^2} \\left(\\left<E^2\\right> - \\left<E\\right>^2\\right)  $$\n",
    "\n",
    "$$ \\chi = \\frac{1}{k_BT} \\left(\\left<M^2\\right> - \\left<M\\right>^2\\right) $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "from ising_model import get_data\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_Cv(E: np.ndarray, T: float, kb: float = 1) -> float:\n",
    "    return 1/(kb*T**2) * np.var(E)\n",
    "\n",
    "calc_Cv_vectorized = np.vectorize(calc_Cv, excluded=[\"E\"], signature=\"(m),()->()\")\n",
    "\n",
    "def calc_chi(M: np.ndarray, kbT: float) -> float:\n",
    "    return 1/(kbT) * np.var(np.abs(M))\n",
    "\n",
    "calc_chi_vectorized = np.vectorize(calc_chi, excluded=[\"M\"], signature=\"(m),()->()\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Es_20, Ms_20, Ts = get_data(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cvs_20 = calc_Cv_vectorized(Es_20, Ts)\n",
    "chis_20 = calc_chi_vectorized(Ms_20, Ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.suptitle(\"Verification plot\")\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(Ts, Cvs_20 / 20**2, label=\"L=20\")\n",
    "plt.xlabel(\"T\")\n",
    "plt.legend()\n",
    "plt.title(\"Cv\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(Ts, chis_20, label=\"L=20\")\n",
    "plt.xlabel(\"T\")\n",
    "plt.title(\"$\\\\chi$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) The specific heat CV and magnetic susceptibility χ have maxima, which move with\n",
    "increasing system size L. Determine the temperature corresponding to the maxima\n",
    "for various system sizes and plot them versus $\\frac{1}{L}$. Extrapolate to L → ∞ to obtain\n",
    "an estimate for the critical temperature Tc.\n",
    "Hint: You can use the functions `np.argmax` and `np.polyfit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data for the rest of the notebook\n",
    "Ls = np.unique(np.append(np.arange(5, 30), 2**np.arange(2, 8)))\n",
    "Tcs_Cv = []\n",
    "Tcs_chi = []\n",
    "Cvs = np.empty((Ls.size, Ts.size))\n",
    "chis = np.empty((Ls.size, Ts.size))\n",
    "for i, L in enumerate(Ls):\n",
    "    Es, Ms, Ts = get_data(L)\n",
    "    _Cvs = calc_Cv_vectorized(Es, Ts)\n",
    "    _chis = calc_chi_vectorized(Ms, Ts)\n",
    "\n",
    "    Tc_Cv = Ts[np.argmax(_Cvs)]\n",
    "    Tc_chi = Ts[np.argmax(_chis)]\n",
    "\n",
    "    Tcs_Cv.append(Tc_Cv)\n",
    "    Tcs_chi.append(Tc_chi)\n",
    "\n",
    "    Cvs[i, :] = _Cvs\n",
    "    chis[i, :] = _chis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.subplot(1,3,1)\n",
    "plt.scatter(1/Ls, Tcs_Cv)\n",
    "plt.xlabel(\"1/L\")\n",
    "plt.title(\"Tc from Cv\")\n",
    "plt.subplot(1,3,2)\n",
    "plt.scatter(1/Ls, Tcs_chi)\n",
    "plt.xlabel(\"1/L\")\n",
    "plt.title(\"Tc from $\\\\chi$\")\n",
    "plt.subplot(1,3,3)\n",
    "plt.scatter([*1/Ls, *1/Ls], [*Tcs_Cv, *Tcs_chi])\n",
    "plt.xlabel(\"1/L\")\n",
    "plt.title(\"Tc\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Cv-data cannot really be extrapolated, as seen on the plot above\n",
    "print(\"== Tc estimates ==\")\n",
    "print(f\" chi  :     {np.polyval(np.polyfit(1/Ls, Tcs_chi, 1), 0) :.3f}\")\n",
    "print(f\" Cv   :     {np.polyval(np.polyfit(1/Ls, Tcs_Cv, 1), 0) :.3f}\")\n",
    "print(f\" both :     {np.polyval(np.polyfit([*1/Ls, *1/Ls], [*Tcs_Cv, *Tcs_chi], 1), 0) :.3f}\")\n",
    "print(f\" exact:     {2 / np.log(1 + np.sqrt(2)) :.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Another quantity which is especially good to obtain the critical temperature is the\n",
    "so-called Binder cumulant, introduced by Binder in 1981 and defined as\n",
    "\n",
    "$$ U_B = \\frac{3}{2}\\left(1 - \\frac{\\left<M^4\\right>}{3\\left<M^2\\right>^2}\\right) $$\n",
    "\n",
    "Plot the Binder cumulant for various system sizes. Find the crossings of UB between\n",
    "curves corresponding to L and 2L, and include them into the previous plot from b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binder_cumulant(Ms: np.ndarray) -> float:\n",
    "    M4 = np.mean(Ms**4)\n",
    "    M22 = np.mean(Ms**2)**2\n",
    "    return 1.5 * (1 - M4 / (3*M22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ls_UB = 2**np.arange(2, 8)\n",
    "UBs = np.empty((Ls_UB.size, Ts.size))\n",
    "\n",
    "for i, L in enumerate(Ls_UB):\n",
    "    Es, Ms, Ts = get_data(L)\n",
    "    for j in range(Ts.size):\n",
    "        UB = binder_cumulant(Ms[j, :])\n",
    "        UBs[i, j] = UB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Binder cumulant\")\n",
    "for i, L in enumerate(Ls_UB):\n",
    "    plt.plot(Ts, UBs[i], label=f\"{L = }\")\n",
    "plt.xlabel(\"T\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find intersection by inspection\n",
    "T_UB = 2.265"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right at the critical temperature TC , the (infinite) system becomes scale invariant. As\n",
    "one approaches the critical point, different macroscopic quantities scale with a power law\n",
    "in τ ≡ $\\frac{T - T_C}{T_C}$. The exponents of these power laws are universal, i.e., they can coincide for\n",
    "systems with different microscopic descriptions (which defines the “universality class”).\n",
    "For example, the correlation length diverges as ξ ∝ |τ |−ν , the specific heat as CV ∝ |τ |−α,\n",
    "the order parameter in the ordered phases as |M | ∝ (−τ )β , and the susceptibility as\n",
    "χ ∝ |τ |−γ . The correlation length of a finite system is bounded by the system size L.\n",
    "From that, one can derive a universal finite size scaling near the critical point.\n",
    "\n",
    "d) Instead of viewing finite-size effect as a nuisance in cutting off power laws, one\n",
    "can exploit the dependency of critical exponents on system size L to extract the\n",
    "exponents. Recall the maxima value of specific heat CV and magnetic susceptibility\n",
    "χ are cut off by\n",
    "\n",
    "$$ \\chi \\sim L^\\frac{\\gamma}{\\nu} $$\n",
    "\n",
    "$$ C_V \\sim L^\\frac{\\alpha}{\\nu} $$\n",
    "\n",
    "Find out the ratio $\\frac{\\gamma}{\\nu}$ and $\\frac{\\alpha}{\\nu}$.\n",
    "Hint: You can use the functions `plt.loglog` and `np.polyfit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.loglog(1/Ls, Tcs_chi)\n",
    "plt.loglog(1/Ls, Tcs_Cv)\n",
    "plt.show()\n",
    "print(\"gamma / nu\", np.polyfit(1/Ls, np.log(Tcs_chi), 1)[1])\n",
    "print(\"alpha / nu\", np.polyfit(1/Ls, np.log(Tcs_Cv), 1)[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) The binder cumulant has the finite size scaling\n",
    "\n",
    "$$ \\Phi_{U_B}\\left(\\tau L^\\frac{1}{\\nu}\\right) $$\n",
    "\n",
    "\n",
    "where ΦUB is an unknown, universal function. Plot UB versus $\\tau L^\\frac{1}{\\nu}$ for various L.\n",
    "Vary the unknown exponent ν until the curves all appear on a single line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Animation to make finding nu easier\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib.widgets import Slider\n",
    "\n",
    "fig, (slider_ax, function_ax) = plt.subplots(1, 2)\n",
    "\n",
    "animation_nu = [1]    # default 1, use list to make updating easier\n",
    "Tc = 2 / np.log(1 + np.sqrt(2)) # ad hoc\n",
    "tau = (Ts - Tc) / Tc\n",
    "\n",
    "nu_slider = Slider(slider_ax, '$\\\\nu$ ', valmin=0, valmax=5, \n",
    "            valinit=animation_nu[0], valfmt='%.2f', facecolor='#cc7000')\n",
    "\n",
    "def update_nu(_nu):\n",
    "    animation_nu[0] = _nu\n",
    "nu_slider.on_changed(update_nu)\n",
    "\n",
    "function_ax.set_xlabel(\"$\\\\tau L^\\\\frac{1}{\\\\nu}$\")\n",
    "function_ax.set_ylabel(\"$U_B$\")\n",
    "\n",
    "plots = []\n",
    "for i, L in enumerate(Ls_UB):\n",
    "\n",
    "    plot ,= function_ax.plot(tau * L**(1 / animation_nu[0]), UBs[i])\n",
    "    plots.append(plot)\n",
    "\n",
    "def animation(_):\n",
    "    for i, L in enumerate(Ls_UB):\n",
    "        plots[i].set_data(tau * L**(1 / animation_nu[0]), UBs[i])\n",
    "    x = tau * Ls[-1]**(1 / animation_nu[0])\n",
    "    function_ax.set_xlim(np.min(x)*1.1, np.max(x)*1.1)\n",
    "\n",
    "ani = FuncAnimation(fig, animation, blit=False, interval=50)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By inspection\n",
    "optimal_nu = animation_nu[0]\n",
    "optimal_nu"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) The susceptibility and specific heat scale as\n",
    "\n",
    "$$ \\chi = L^\\frac{\\gamma}{\\nu}\\Phi_{\\chi}\\left(\\tau L^\\frac{1}{\\nu}\\right) $$\n",
    "\n",
    "\n",
    "$$ C_V = L^\\frac{\\alpha}{\\nu}\\Phi_{C_V}\\left(\\tau L^\\frac{1}{\\nu}\\right) $$\n",
    "\n",
    "with other unknown scaling functions Φχ, ΦCV . Try to find the exponents γ and α\n",
    "by plotting χ/$L^\\frac{\\gamma}{\\nu}$ and CV /L^\\frac{\\alpha}{\\nu}$ versus τ$L^\\frac{1}{\\nu}$$ and varying the exponents until you get\n",
    "a data collapse. How well is the hyperscaling relation νd = 2 − α fulfilled?\n",
    "Hint: While for an exponent α = 0 formally CV ∝ τ −α = const., the leading scaling\n",
    "behaviour is in this case CV ∝ − log(τ ). For the finite size scaling, this means\n",
    "CV = $\\log(L)\\Phi_{C_V}\\left(\\tau L^\\frac{1}{\\nu}\\right)$\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (slider_ax, function_ax) = plt.subplots(1, 2)\n",
    "\n",
    "animation_gamma = [1]    # default 1, use list to make updating easier\n",
    "Tc = 2 / np.log(1 + np.sqrt(2)) # ad hoc\n",
    "tau = (Ts - Tc) / Tc\n",
    "\n",
    "gamma_slider = Slider(slider_ax, '$\\\\nu$ ', valmin=0, valmax=5, \n",
    "            valinit=animation_nu[0], valfmt='%.2f', facecolor='#cc7000')\n",
    "\n",
    "def update_gamma(_gamma):\n",
    "    animation_gamma[0] = _gamma\n",
    "gamma_slider.on_changed(update_gamma)\n",
    "\n",
    "function_ax.set_xlabel(\"$\\\\tau L^\\\\frac{1}{\\\\nu}$\")\n",
    "function_ax.set_ylabel(\"$\\\\chi / L^\\\\frac{\\\\gamma}{\\\\nu}$\")\n",
    "\n",
    "function_ax.set_xlim(-20, 20)\n",
    "\n",
    "plots = []\n",
    "for i, L in enumerate(Ls):\n",
    "\n",
    "    plot ,= function_ax.plot(tau * L**(1 / optimal_nu), chis[i] / L**(animation_gamma[0] / optimal_nu))\n",
    "    plots.append(plot)\n",
    "\n",
    "def animation(_):\n",
    "    for i, L in enumerate(Ls):\n",
    "        plots[i].set_data(tau * L**(1 / optimal_nu), chis[i] / L**(animation_gamma[0] / optimal_nu))\n",
    "    y = chis[i] / Ls[-1]**(animation_gamma[0] / optimal_nu)\n",
    "    function_ax.set_ylim(np.min(y)*1.1, np.max(y)*1.1)\n",
    "\n",
    "ani = FuncAnimation(fig, animation, blit=False, interval=50)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_gamma = animation_gamma[0]\n",
    "optimal_gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (slider_ax, function_ax) = plt.subplots(1, 2)\n",
    "\n",
    "animation_alpha = [1]    # default 1, use list to make updating easier\n",
    "Tc = 2 / np.log(1 + np.sqrt(2)) # ad hoc\n",
    "tau = (Ts - Tc) / Tc\n",
    "\n",
    "alpha_slider = Slider(slider_ax, '$\\\\nu$ ', valmin=0, valmax=5, \n",
    "            valinit=animation_nu[0], valfmt='%.2f', facecolor='#cc7000')\n",
    "\n",
    "def update_alpha(_alpha):\n",
    "    animation_alpha[0] = _alpha\n",
    "alpha_slider.on_changed(update_alpha)\n",
    "\n",
    "function_ax.set_xlabel(\"$\\\\tau L^\\\\frac{1}{\\\\nu}$\")\n",
    "function_ax.set_ylabel(\"$Cv / L^\\\\frac{\\\\alpha}{\\\\nu}$\")\n",
    "\n",
    "function_ax.set_xlim(-20, 20)\n",
    "\n",
    "plots = []\n",
    "for i, L in enumerate(Ls):\n",
    "\n",
    "    plot ,= function_ax.plot(tau * L**(1 / optimal_nu), Cvs[i] / L**(animation_alpha[0] / optimal_nu))\n",
    "    plots.append(plot)\n",
    "\n",
    "def animation(_):\n",
    "    for i, L in enumerate(Ls):\n",
    "        plots[i].set_data(tau * L**(1 / optimal_nu), Cvs[i] / L**(animation_alpha[0] / optimal_nu))\n",
    "    y = Cvs[i] / Ls[-1]**(animation_alpha[0] / optimal_nu)\n",
    "    function_ax.set_ylim(np.min(y)*1.1, np.max(y)*1.1)\n",
    "\n",
    "ani = FuncAnimation(fig, animation, blit=False, interval=50)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_alpha = animation_alpha[0]\n",
    "optimal_alpha"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g) Modify the program generating the Monte carlo data to simulate the (ferromagnetic)\n",
    "Ising model on a triangular lattice. (For the provided program, this requires only to\n",
    "add 2 lines (and maybe changing output filename)!). Find the critical temperature.\n",
    "Are the critical exponents the same as on the square lattice, i.e., are these two\n",
    "models in the same universality class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I re-ran the entire notebook, where I imported the triangular model instead of the square one.\n",
    "# The results were as follows:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
